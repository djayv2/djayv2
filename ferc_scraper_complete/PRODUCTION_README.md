# FERC Scraper - Production Deployment

A production-ready Python scraper for FERC database downloads, dockerized and configured for external PostgreSQL database.

## üéØ **Specifications Met**

‚úÖ **Primarily written in Python**  
‚úÖ **Dockerized (runs inside Docker image)**  
‚úÖ **Outputs all data to PostgreSQL database using pg8000 driver**  
‚úÖ **Uses schema: test_external**  
‚úÖ **Returns tables in proper SCD1/SCD2 format**  
‚úÖ **Suitable suite of pytest tests**  
‚úÖ **Schema already exists (no creation in script)**  

## üóÑÔ∏è **Database Configuration**

- **Host**: 34.59.88.3
- **Port**: 5432
- **Database**: postgres
- **Username**: jay_semia
- **Password**: $..q)kf:=bCqw4fZ
- **Schema**: test_external
- **Driver**: pg8000

## üöÄ **Quick Start**

### 1. **Deploy with Docker**

```bash
# Build and run
docker-compose up -d

# View logs
docker-compose logs -f ferc-scraper

# Check status
docker-compose ps
```

### 2. **Manual Docker Deployment**

```bash
# Build image
docker build -t ferc-scraper .

# Run with environment variables
docker run -d \
  -e DB_HOST=34.59.88.3 \
  -e DB_PORT=5432 \
  -e DB_NAME=postgres \
  -e DB_USER=jay_semia \
  -e DB_PASSWORD='$..q)kf:=bCqw4fZ' \
  -e DB_SCHEMA=test_external \
  -e CREATE_TABLES=false \
  -e SCD_TYPE=2 \
  --name ferc-scraper \
  ferc-scraper
```

## üß™ **Testing**

### Run All Tests

```bash
# Activate virtual environment
source venv/bin/activate

# Run unit tests
python -m pytest tests/ -v

# Run database integration tests
python tests/test_database_integration.py

# Run production test
python test_production_scraper.py
```

### Test Database Connection

```bash
# Test connection to external database
python -c "
import os
os.environ['DB_HOST'] = '34.59.88.3'
os.environ['DB_USER'] = 'jay_semia'
os.environ['DB_PASSWORD'] = '$..q)kf:=bCqw4fZ'
os.environ['DB_SCHEMA'] = 'test_external'

from src.ferc_scraper.config import get_settings
from src.ferc_scraper.storage import PostgresStorage

settings = get_settings()
with PostgresStorage(settings) as storage:
    cursor = storage._conn.cursor()
    cursor.execute('SELECT version()')
    print('‚úÖ Database connection successful:', cursor.fetchone()[0])
"
```

## üìä **Database Schema**

### Documents Table (SCD2)

```sql
-- Located in test_external.documents
CREATE TABLE test_external.documents (
    id SERIAL PRIMARY KEY,
    source VARCHAR(50) NOT NULL,
    document_id VARCHAR(255) NOT NULL,
    url TEXT NOT NULL,
    title TEXT NOT NULL,
    published_at TIMESTAMP,
    content_text TEXT,
    content_hash VARCHAR(64),
    extra JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    is_current BOOLEAN DEFAULT TRUE,
    valid_from TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    valid_to TIMESTAMP DEFAULT '9999-12-31 23:59:59'
);
```

### Raw Data Table

```sql
-- Located in test_external.ferc_raw
CREATE TABLE test_external.ferc_raw (
    id SERIAL PRIMARY KEY,
    source_url TEXT NOT NULL,
    dataset_name VARCHAR(255),
    row_data JSONB,
    ingested_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    file_hash VARCHAR(64)
);
```

## üîß **Configuration**

### Environment Variables

```bash
# Database (External)
DB_HOST=34.59.88.3
DB_PORT=5432
DB_NAME=postgres
DB_USER=jay_semia
DB_PASSWORD=$..q)kf:=bCqw4fZ
DB_SCHEMA=test_external
DB_SSLMODE=prefer

# Scraper
BASE_URL=https://www.ferc.gov/download-database
SCRAPER_MODE=dbindex
MAX_PAGES=1
FETCH_DETAILS=false
REQUEST_TIMEOUT_SECONDS=30
MAX_RETRIES=3
SCD_TYPE=2

# Data Processing
CREATE_TABLES=false
INGEST_DATASETS=true
RAW_TABLE=ferc_raw
```

## üìà **SCD Implementation**

### SCD Type 2 (Recommended)

- **Versioning**: Each document change creates a new version
- **History**: Previous versions are preserved with `valid_from`/`valid_to`
- **Current Flag**: `is_current` indicates the active version
- **Audit Trail**: Complete history of all changes

### Example SCD2 Data

```sql
-- Query to see document history
SELECT 
    document_id,
    title,
    is_current,
    valid_from,
    valid_to
FROM test_external.documents 
WHERE document_id = 'form-1-2024.zip'
ORDER BY valid_from DESC;
```

## üê≥ **Docker Configuration**

### Dockerfile Features

- **Base Image**: Python 3.11-slim
- **Chrome/ChromeDriver**: For Cloudflare bypass
- **Security**: Non-root user (scraper:1000)
- **Health Checks**: Built-in monitoring
- **Optimized**: Multi-stage build for smaller image

### Docker Compose

```yaml
version: '3.8'
services:
  ferc-scraper:
    build: .
    environment:
      DB_HOST: 34.59.88.3
      DB_USER: jay_semia
      DB_PASSWORD: $..q)kf:=bCqw4fZ
      DB_SCHEMA: test_external
      CREATE_TABLES: false
      SCD_TYPE: 2
    restart: unless-stopped
```

## üîç **Monitoring**

### Health Checks

```bash
# Check scraper health
docker-compose exec ferc-scraper python -c "import sys; sys.exit(0)"

# Check database connectivity
docker-compose exec ferc-scraper python -c "
from src.ferc_scraper.config import get_settings
from src.ferc_scraper.storage import PostgresStorage
settings = get_settings()
with PostgresStorage(settings) as storage:
    print('Database connection: OK')
"
```

### Logs

```bash
# View scraper logs
docker-compose logs -f ferc-scraper

# View recent logs
docker-compose logs --tail=100 ferc-scraper

# View error logs
docker-compose logs ferc-scraper | grep ERROR
```

## üìã **Data Flow**

1. **Scraper** ‚Üí Fetches FERC database download page
2. **Parser** ‚Üí Extracts download links (.zip, .csv files)
3. **Storage** ‚Üí Stores metadata in `test_external.documents` (SCD2)
4. **Ingestion** ‚Üí Downloads and processes data files
5. **Raw Storage** ‚Üí Stores processed data in `test_external.ferc_raw`

## üö® **Troubleshooting**

### Database Connection Issues

```bash
# Test direct connection
psql -h 34.59.88.3 -U jay_semia -d postgres -c "SELECT version();"

# Check SSL connection
psql -h 34.59.88.3 -U jay_semia -d postgres -c "SHOW ssl;" 
```

### Cloudflare Issues

If Cloudflare blocking occurs:
1. Increase `REQUEST_TIMEOUT_SECONDS=60`
2. Add proxy configuration
3. Check Selenium logs for details

### Container Issues

```bash
# Check container status
docker-compose ps

# Restart scraper
docker-compose restart ferc-scraper

# View resource usage
docker-compose stats
```

## üìä **Performance**

### Expected Performance

- **Scraping Speed**: ~5-10 documents per minute
- **Database Writes**: Optimized with batch inserts
- **Memory Usage**: ~200-500MB per container
- **Storage**: Minimal (data stored in external database)

### Optimization

- **Connection Pooling**: pg8000 handles connection management
- **Batch Processing**: Multiple documents processed together
- **Indexing**: Database indexes on frequently queried columns
- **Caching**: Selenium session reuse for multiple requests

## üîí **Security**

- **Non-root User**: Container runs as user `scraper:1000`
- **SSL Support**: pg8000 SSL handling for secure database connections
- **Environment Variables**: Sensitive data passed via environment
- **Network Isolation**: Containerized deployment

## üìù **Logs and Debugging**

### Log Levels

- **INFO**: Normal operation messages
- **WARNING**: Non-critical issues (retries, timeouts)
- **ERROR**: Critical failures (connection issues, parsing errors)

### Debug Mode

```bash
# Enable debug logging
docker run -e LOG_LEVEL=DEBUG ferc-scraper
```

## ‚úÖ **Verification Checklist**

- [ ] Docker image builds successfully
- [ ] Database connection established
- [ ] Schema `test_external` accessible
- [ ] SCD2 tables exist and functional
- [ ] Scraper can fetch FERC data
- [ ] Data properly stored in PostgreSQL
- [ ] All tests pass
- [ ] Health checks working
- [ ] Logs showing successful operation

---

**Production Ready**: This scraper is configured for production deployment with external database, comprehensive testing, and proper SCD2 data warehousing.